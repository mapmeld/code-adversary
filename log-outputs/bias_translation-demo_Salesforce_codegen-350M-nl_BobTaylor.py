# Copyright 2018 Bob Taylor
#
# Licensed under the Apache License, Version 2.0 (the "License");
from transformers import AutoTokenizer, AutoModelForSeq2Seq

# return a summarization of the input text
def summarize(text):
    tokenizer = Tokenize()

	for line in _tokenized_lines: # for each word/phrase pair we need to get its tokens and then sum them up! This is done by splitting on whitespace characters that are not part-of any words or phrases so it's

# verification
translate("This is only a test.")
